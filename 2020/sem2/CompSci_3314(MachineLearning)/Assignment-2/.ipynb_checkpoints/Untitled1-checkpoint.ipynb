{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Adaboost:\n",
    "    \n",
    "    # Adaboost Class Constructor \n",
    "    def __init__(self,Train_X,Train_Y,Test_X,Test_Y,Num_Of_Classifier):\n",
    "        self.Train_X = Train_X\n",
    "        self.Train_Y = Train_Y\n",
    "        self.Test_X = Test_X\n",
    "        self.Test_Y = Test_Y\n",
    "        self.Num_Of_Classifier = Num_Of_Classifier # The Number base estimator (Decision Stump)\n",
    "        self.alpha = None # Stores the alpha value for each Decision Stump in each interation (Example: i=10, store alpha for decision stump number 10)\n",
    "        self.Weak_Classifier = None # Stores the number of base estimator (Decision Stump)\n",
    "        self.accuracy = [] # Stores the accuracy for each Decision Stump \n",
    "        self.training_error = [] # Stores the traning data predictions \n",
    "        self.testing_error = [] # Stores the testing data predictions \n",
    "    \n",
    "    \n",
    "    # Fitting the Decision Stump based on the Training Dataset Given\n",
    "    def Build_Model(self):\n",
    "        #Temp_Arr = self.Train_X.copy()\n",
    "        #Temp_Arr[\"Weights\"] = 1/len(self.Train_X)\n",
    "        \n",
    "        # Extract The Dimension of Train_X data\n",
    "        num_X, num_Y = np.shape(self.Train_X)\n",
    "        \n",
    "        # Set the initial Weight for each of the Train_X data\n",
    "        weight = np.full(num_X, (1 / num_X))\n",
    "    \n",
    "        #Transpose_Train_Y = self.Train_Y.T\n",
    "        \n",
    "        train_pred = np.zeros(len(self.Train_X))\n",
    "        test_pred = np.zeros(len(self.Train_Y))\n",
    "        \n",
    "        # Temporary Arrays to store the corresponding alpha and based estimator of each Decision Stump\n",
    "        alphas = []\n",
    "        models = []\n",
    "        pred = []\n",
    "        pred_2 = []\n",
    "        Temp = []\n",
    "        Temp2 = []\n",
    "        Temp_Test = []\n",
    "        Temp2_Test = []\n",
    "        \n",
    "        \n",
    "        # This is where we construct/train the Decision Stump Model\n",
    "        for index in range(self.Num_Of_Classifier):\n",
    "            \n",
    "            # Build the Generic Decision Stump\n",
    "            # Entropy is used here to select the best performing Decision tree in each iteration based on how good a feature can split the Train_X data into \n",
    "            clf = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
    "            \n",
    "            # Fit the Decision Stump with the corresponding Train_X data and Train_Y label and the data weights \n",
    "            Model = clf.fit(np.float32(self.Train_X),np.float32(self.Train_Y), sample_weight=np.array(weight))\n",
    "            \n",
    "            # Store the Fitted Decision Stump intp the models array\n",
    "            models.append(Model)\n",
    "            \n",
    "            # Produce the predicted labels[1,-1] based on the Train_X data using the current ith Decision Stump\n",
    "            predictions = clf.predict(np.float32(self.Train_X))\n",
    "            predictions_2 = clf.predict(np.float32(self.Test_X))\n",
    "            pred.append(predictions)\n",
    "            pred_2.append(predictions_2)\n",
    "            score = Model.score(np.float32(self.Train_X),np.float32(self.Train_Y), sample_weight=np.array(weight))\n",
    "            #error = 1 - score;\n",
    "            #Temp_Arr[\"predictions\"] = predictions\n",
    "            \n",
    "            \n",
    "#           # Calculate the prediction and misclassification\n",
    "#             Temp_Arr['correctly_classified'] = np.where(Temp_Arr['predictions'] == self.Train_Y['M'],1,0)\n",
    "            Temp_Misclassified = np.where(predictions != self.Train_Y['M'],1,0)\n",
    "               \n",
    "            \n",
    "# #             print(Temp_Arr['correctly_classified'])\n",
    "# #             print(Temp_Arr['misclassified'])\n",
    "            \n",
    "#             # Calculate the misclassification and accuracy\n",
    "#             accuracy = sum(Temp_Arr['correctly_classified'])/len(Temp_Arr['correctly_classified'])\n",
    "#             misclassification = sum(Temp_Arr['misclassified'])/len(Temp_Arr['misclassified'])\n",
    "            \n",
    "#             print(accuracy)\n",
    "#             print(misclassification)\n",
    "            \n",
    "            # Caclulate the error\n",
    "            #error = np.sum(Temp_Arr['Weights']*Temp_Arr['misclassified']) / sum(Temp_Arr['Weights'])\n",
    "            \n",
    "            # Caclulate the error\n",
    "            error = np.sum(weight[predictions != self.Train_Y['M']])\n",
    "            \n",
    "            # Calculate the alpha values\n",
    "            al = np.log((1-error)/error)\n",
    "            alphas.append(al)\n",
    "            \n",
    "            # Calculate the new weight for each of the data in Train_X\n",
    "            T = np.sign(self.Train_Y['M'] * predictions)\n",
    "            #print(T)\n",
    "            #weight = np.multiply(weight, np.exp([float(x) * -al for x in T]))\n",
    "            weight *= np.exp(al*Temp_Misclassified)\n",
    "            weight /= np.sum(weight) # Normalise the weight of each data \n",
    "            #print(np.sum(weight))\n",
    "            #Temp_Arr['Weights'] *= np.exp(-al)\n",
    "#             Temp_Arr['Weights'] *= np.exp(al*Temp_Arr['misclassified'])\n",
    "#             Temp_Arr['Weights'] *= np.exp(-al*Temp_Arr['correctly_classified'])\n",
    "#             Temp_Arr['Weights'] = Temp_Arr['Weights']/np.sum(Temp_Arr['Weights'])\n",
    "\n",
    "            #Temp_Arr['Weights'] = np.multiply(Temp_Arr['Weights'], np.exp([float(x) * al for x in Temp_Arr['correctly_classified']]))\n",
    "            #Temp_Arr['Weights'] = np.multiply(Temp_Arr['Weights'], np.exp([float(x) * -al for x in Temp_Arr['misclassified']]))\n",
    "            \n",
    "            #Temp_Arr['Weights'] = Temp_Arr['Weights']/np.sum(Temp_Arr['Weights'])\n",
    "            \n",
    "            # Calculate the training_error \n",
    "            Temp = np.sign(np.sum(np.array(pred),axis=0))\n",
    "            Temp2 = np.where(Temp == self.Train_Y['M'],1,0)\n",
    "            \n",
    "            self.training_error.append(1-(np.sum(Temp2)/len(pred[0])))\n",
    "            \n",
    "            Temp_Test = np.sign(np.sum(np.array(pred_2),axis=0))\n",
    "            Temp2_Test = np.where(Temp_Test == self.Test_Y['M'],1,0)\n",
    "            \n",
    "            self.testing_error.append(1-(np.sum(Temp2_Test)/len(pred_2[0])))\n",
    "                                                                           \n",
    "# #             print(Temp_Arr[\"Weights\"])\n",
    "#             print(np.sum(Temp_Arr[\"Weights\"]))\n",
    "            \n",
    "#             print(alphas)\n",
    "        \n",
    "        # Stores the corresponding alphas and models array into the Adaboost Constructor \n",
    "        self.alpha = alphas\n",
    "        self.Weak_Classifier = models\n",
    "        #self.training_error = np.sign(np.sum(np.array(pred), axis=0))\n",
    "    \n",
    "    def predict(self):\n",
    "        accuracy = []\n",
    "        predictions = []\n",
    "        \n",
    "        Temp = []\n",
    "        Temp2 = []\n",
    "        \n",
    "        # Calculate the accuracy of each Decision Stump on the Testing dataset \n",
    "        for al,clf in zip(self.alpha,self.Weak_Classifier):\n",
    "            prediction = al*clf.predict(np.float32(self.Test_X))\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "            Temp = np.sign(np.sum(np.array(predictions),axis=0))\n",
    "            Temp2 = np.where(Temp == self.Test_Y['M'],1,0)\n",
    "            \n",
    "            self.accuracy.append(np.sum(Temp2)/len(predictions[0]))\n",
    "            \n",
    "            # Calculate the testing error\n",
    "            #self.testing_error.append(1-(np.sum(Temp2)/len(predictions[0])))\n",
    "            \n",
    "            #self.testing_predictions = np.sign(np.sum(np.array(predictions),axis=0))\n",
    "        \n",
    "       \n",
    "        \n",
    "            \n",
    "# #             print(np.sum(Temp_Arr['Weights']))\n",
    "            \n",
    "            \n",
    "# #         self.alpha = alphas\n",
    "# #         self.Weak_Classifier = mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Import The Dataset \n",
    "\"\"\"\n",
    "\n",
    "#Import the Dataset\n",
    "dataset = pd.read_csv(\"wdbc_data.csv\")\n",
    "\n",
    "training_Y = dataset.iloc[0:300,[1]]\n",
    "training_X = dataset.iloc[0:300,2:]\n",
    "\n",
    "testing_Y = dataset.iloc[300:,[1]]\n",
    "testing_X = dataset.iloc[300:,2:]\n",
    "\n",
    "training_Y[training_Y=='M']=1\n",
    "training_Y[training_Y=='B']=-1\n",
    "\n",
    "testing_Y[testing_Y=='M']=1\n",
    "testing_Y[testing_Y=='B']=-1\n",
    "\n",
    "\n",
    "# Model = Adaboost(training_X, training_Y, testing_X, testing_Y, 1)\n",
    "# Model.Build_Model()\n",
    "# Model.predict()\n",
    "\n",
    "# len(Model.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_base_learners = 10\n",
    "\n",
    "Temp_accuracy = []\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig2 = plt.figure(figsize=(10,10))\n",
    "ax0 = fig.add_subplot(111)\n",
    "err0 = fig2.add_subplot(111)\n",
    "\n",
    "\n",
    "for i in range(1, number_of_base_learners+1):\n",
    "    model = Adaboost(training_X, training_Y, testing_X, testing_Y, i)\n",
    "    model.Build_Model()\n",
    "    model.predict()\n",
    "\n",
    "train_Y = np.squeeze(np.asarray(training_Y))\n",
    "test_Y = np.squeeze(np.asarray(testing_Y))\n",
    "\n",
    "# Sklearn AdaboostClassifier Implementation \n",
    "for i in range(1, number_of_base_learners+1):\n",
    "    AdaBoost = AdaBoostClassifier(n_estimators=i,learning_rate=1,algorithm='SAMME')\n",
    "    AdaBoost.fit(np.float32(training_X), np.float32(train_Y)) \n",
    "    pred = AdaBoost.predict(testing_X)\n",
    "#     s = 0\n",
    "#     for k in range(len(pred)):\n",
    "#         if pred[k] == test_Y[k]:\n",
    "#             s = s + 1\n",
    "            \n",
    "#     acc = s/len(pred)\n",
    "    #oo = np.where(pred == test_Y['M'], 1, 0)\n",
    "    print(pred.shape)\n",
    "    prediction = AdaBoost.score(np.float32(testing_X), np.float32(test_Y))\n",
    "#     Temp_accuracy.append(acc)\n",
    "    Temp_accuracy.append(prediction)\n",
    "    \n",
    "# print(model.training_error)\n",
    "# print(model.testing_error)\n",
    "    \n",
    "ax0.plot(range(len(model.accuracy)),model.accuracy,'-b')\n",
    "ax0.plot(range(len(Temp_accuracy)), Temp_accuracy, 'r--')\n",
    "ax0.set_xlabel('Number of base Model used for boosting')\n",
    "ax0.set_ylabel('Accuracy')\n",
    "\n",
    "err0.plot(range(len(model.training_error)),model.training_error,'-b', range(len(model.testing_error)), model.testing_error, 'r--')\n",
    "err0.set_xlabel('Number of iterations')\n",
    "err0.set_ylabel('Error Rate')\n",
    "print('With a number of ',number_of_base_learners,'base models we receive an accuracy of ',model.accuracy[-1]*100,'%')    \n",
    "                 \n",
    "plt.show()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
